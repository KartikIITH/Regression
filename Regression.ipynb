{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "- Simple linear regression is a statistical method used to model the relationship between one independent variable and one dependent variable by fitting a straight line to the data"
      ],
      "metadata": {
        "id": "s_9WHwvz_ARv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "- Linearity: The relationship between variables is linear.\n",
        "\n",
        "- Independence of errors: Residuals are independent.\n",
        "\n",
        "- Homoscedasticity: Residuals have constant variance.\n",
        "\n",
        "- Normality of residuals: Residuals follow a normal distribution"
      ],
      "metadata": {
        "id": "J5vhI2Na_FWS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zlCT5ehByDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.What does the coefficient\n",
        "m\n",
        "m represent in\n",
        "Y\n",
        "=\n",
        "m\n",
        "x\n",
        "+\n",
        "c\n",
        "Y=mx+c?\n",
        "- The coefficient\n",
        "m\n",
        "m represents the slope or gradient of the line, indicating how much the dependent variable changes for a unit change in the independent variable"
      ],
      "metadata": {
        "id": "e4JkEodX_NOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept\n",
        "\n",
        "Y\n",
        "=\n",
        "m\n",
        "x\n",
        "+\n",
        "c\n",
        "- Y=mx+c?\n",
        "- The intercept\n",
        " c represents the point where the line crosses the y-axis, i.e., the value of\n",
        "Y\n",
        "Y when\n",
        "X\n",
        "=\n",
        "0\n",
        "X=0"
      ],
      "metadata": {
        "id": "QjtMAF8b_ShG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do we calculate the slope\n",
        "m\n",
        "m in Simple Linear Regression?\n",
        "The slope is calculated as:\n",
        "\n",
        "- m\n",
        "=\n",
        "∑\n",
        "(\n",
        "x\n",
        "i\n",
        "−\n",
        "x\n",
        "ˉ\n",
        ")\n",
        "(\n",
        "y\n",
        "i\n",
        "−\n",
        "y\n",
        "ˉ\n",
        ")/\n",
        "∑\n",
        "(\n",
        "x\n",
        "i\n",
        "−\n",
        "x\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "\n"
      ],
      "metadata": {
        "id": "gjybKWsU_WO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "- The least squares method minimizes the sum of squared residuals (differences between observed and predicted values), ensuring the best fit for the regression line"
      ],
      "metadata": {
        "id": "4cJqKZdv_ca-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is R² interpreted in Simple Linear Regression?\n",
        "- R² measures how well the independent variable explains variations in the dependent variable. An R² of 1 indicates perfect prediction, while 0 indicates no explanatory power"
      ],
      "metadata": {
        "id": "aXbJQT80_g_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 .What is Multiple Linear Regression?\n",
        "- Multiple linear regression models a relationship between one dependent variable and multiple independent variables"
      ],
      "metadata": {
        "id": "GUUPo_J3_phD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "- Simple linear regression uses one independent variable, while multiple regression uses two or more independent variables to predict a dependent variable"
      ],
      "metadata": {
        "id": "rBIlrDK9_t28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "- Linearity between variables.\n",
        "\n",
        "- No multicollinearity among independent variables.\n",
        "\n",
        "- Homoscedasticity of residuals.\n",
        "\n",
        "- Normal distribution of residuals"
      ],
      "metadata": {
        "id": "PbbXgDKd_zle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is heteroscedasticity, and how does it affect results?\n",
        "- Heteroscedasticity occurs when residual variance is not constant, leading to biased standard errors and unreliable statistical tests"
      ],
      "metadata": {
        "id": "RkAi4poQ_7FL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a model with high multicollinearity?\n",
        "\n",
        "- Remove highly correlated predictors.\n",
        "\n",
        "- Use regularization techniques like Ridge or Lasso regression.\n",
        "\n",
        "- Perform principal component analysis (PCA)"
      ],
      "metadata": {
        "id": "T1_U5Gd_AAW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are some techniques for transforming categorical variables?\n",
        "\n",
        "- One-hot encoding.\n",
        "\n",
        "- Label encoding.\n",
        "\n",
        "- Binary encoding"
      ],
      "metadata": {
        "id": "KpPnHjnbAF0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "- Interaction terms capture combined effects of two or more predictors on the dependent variable, helping model complex relationships"
      ],
      "metadata": {
        "id": "Xv3TrA5CANPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How does intercept interpretation differ between Simple and Multiple Linear Regression?\n",
        "- In multiple regression, the intercept represents the predicted value when all independent variables are zero, assuming no interaction effects.\n",
        "\n"
      ],
      "metadata": {
        "id": "YwE0KTQJAT_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Significance of slope in regression analysis:\n",
        "- The slope quantifies how changes in an independent variable affect changes in the dependent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "xc9j87T1AYNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does intercept provide context for relationships?\n",
        "- It gives a baseline value for predictions when all predictors are at zero"
      ],
      "metadata": {
        "id": "aZMCBhZuAbkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Limitations of using R² as a sole measure:\n",
        "- R² does not account for overfitting or irrelevant predictors; adjusted R² provides a better measure by penalizing model complexity"
      ],
      "metadata": {
        "id": "HaXLnq7kAfiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Interpreting large standard errors for coefficients:\n",
        "- Large standard errors suggest high variability in coefficient estimates, possibly due to multicollinearity or insufficient data."
      ],
      "metadata": {
        "id": "8tKbXg0SAkhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How can heteroscedasticity be identified and addressed?\n",
        "- Identified via residual plots; addressed using transformations (e.g., log transformation) or weighted least squares methods"
      ],
      "metadata": {
        "id": "xWo4lH2KApCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does high R² but low adjusted R² mean?\n",
        "- It indicates overfitting due to irrelevant predictors inflating R² without improving model performance."
      ],
      "metadata": {
        "id": "LqZ4a5I3As37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why scale variables in Multiple Linear Regression?\n",
        "- Scaling ensures that predictors with different units contribute equally to model performance."
      ],
      "metadata": {
        "id": "dHLipbLAAwxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is Polynomial Regression?\n",
        "- Polynomial regression models non-linear relationships by fitting a polynomial equation to data."
      ],
      "metadata": {
        "id": "pIN3-6CqA15h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How does it differ from linear regression?\n",
        "- Polynomial regression fits curves instead of straight lines, allowing it to capture non-linear patterns."
      ],
      "metadata": {
        "id": "xvP0bTiBA6Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "- When data shows non-linear trends that cannot be captured by simple linear models."
      ],
      "metadata": {
        "id": "dP6SEMK-A_Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26.  General equation for polynomial regression:\n",
        "\n",
        "Y\n",
        "=\n",
        "b\n",
        "0\n",
        "+\n",
        "b\n",
        "1\n",
        "X\n",
        "+\n",
        "b\n",
        "2\n",
        "X\n",
        "2\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "b\n",
        "n\n",
        "X\n",
        "n\n",
        "+\n",
        "ϵ\n"
      ],
      "metadata": {
        "id": "y94NvM0VBDOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can it be applied to multiple variables?\n",
        "- Yes, polynomial terms can be added for each predictor"
      ],
      "metadata": {
        "id": "sbKWlal0BPrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Limitations of polynomial regression\n",
        "- It may overfit data if too many terms are added and becomes computationally expensive with higher degrees.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MkcveoFmBTjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Methods to evaluate model fit for polynomial degree selection\n",
        "- Use cross-validation or metrics like adjusted R² and AIC/BIC scores."
      ],
      "metadata": {
        "id": "t6CYxjY4Bd1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Importance of visualization in polynomial regression\n",
        "- Visualizations help assess how well curves fit observed data."
      ],
      "metadata": {
        "id": "xGjHqh-UBiYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python?\n",
        "- Using libraries like scikit-learn with PolynomialFeatures to generate polynomial terms and LinearRegression for fitting."
      ],
      "metadata": {
        "id": "ZFnlqTjyBmdU"
      }
    }
  ]
}